{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6700cb-a0b0-4ac2-8fd5-363729284173",
   "metadata": {},
   "source": [
    "# AI-Powered Resume Analyzer for Job Postings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa4891-b283-44de-aa63-f017eb9b140d",
   "metadata": {},
   "source": [
    "This tool is designed to analyze resumes against specific job postings, offering valuable insights such as:\n",
    "\n",
    "- Identification of skill gaps\n",
    "- Keyword matching between the CV and the job description\n",
    "- Tailored recommendations for CV improvement\n",
    "- An alignment score reflecting how well the CV fits the job\n",
    "- Personalized feedback \n",
    "- Job market trend insights\n",
    "\n",
    "An example of the tool's output can be found [here](https://tvarol.github.io/sideProjects/AILLMAgents/output.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a6a34ea-191f-4c54-9793-a3eb63faab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import requests\n",
    "import PyPDF2\n",
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "from pdf2image import convert_from_bytes\n",
    "import pytesseract\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "from ipywidgets import Textarea, FileUpload, Button, VBox, HTML\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bbe1d3-bacc-400c-aed2-db44699e38f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "if not api_key:\n",
    "    print(\"No API key was found!!!\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27bfcee1-58e6-4ff2-9f12-9dc5c1aa5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e79f2-3139-4520-ac01-a728c11cb8b9",
   "metadata": {},
   "source": [
    "## Using a Frontier Model GPT-4o Mini for This Project\n",
    "\n",
    "### Types of Prompts\n",
    "\n",
    "Models like GPT4o have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da158ad-c3a8-4cef-806f-be0f90852996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt \n",
    "system_prompt = \"\"\"You are a powerful AI model designed to assist with resume analysis. Your task is to analyze a resume against a given job posting and provide feedback on how well the resume aligns with the job requirements. Your response should include the following: \n",
    "1) Skill gap identification: Compare the skills listed in the resume with those required in the job posting, highlighting areas where the resume may be lacking or overemphasized.\n",
    "2) Keyword matching between a CV and a job posting: Match keywords from the job description with the resume, determining how well they align. Provide specific suggestions for missing keywords to add to the CV.\n",
    "3) Recommendations for CV improvement: Provide actionable suggestions on how to enhance the resume, such as adding missing skills or rephrasing experience to match job requirements.\n",
    "4) Alignment score: Display a score that represents the degree of alignment between the resume and the job posting.\n",
    "5) Personalized feedback: Offer tailored advice based on the job posting, guiding the user on how to optimize their CV for the best chances of success.\n",
    "6) Job market trend insights, provide broader market trends and insights, such as in-demand skills and salary ranges.\n",
    "Provide responses that are concise, clear, and to the point. Respond in markdown.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_text_from_pdf(content):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(content) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\" if page.extract_text() else \"\"\n",
    "    return text\n",
    "\n",
    "def extract_text_with_ocr(pdf_path):\n",
    "    images = convert_from_path(pdf_path)  # Convert PDF pages to images\n",
    "    text = \"\\n\".join(pytesseract.image_to_string(img) for img in images)\n",
    "    return text.strip()\n",
    "\n",
    "# Call the function with the correct argument\n",
    "extracted_text = extract_text_with_ocr(\"resume_dhaneswara_mandrasa.pdf\")\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d49c7a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2812237b8a429d9635ff55fe0b5366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Input Job Posting and CV</h3>'), VBox(children=(Textarea(value='', description=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "job_posting_area = Textarea(\n",
    "    placeholder='Paste the job posting text here...',\n",
    "    description='Job Posting:',\n",
    "    disabled=False,\n",
    "    layout={'width': '800px', 'height': '300px'}\n",
    ")\n",
    "\n",
    "# Define file upload for CV\n",
    "cv_upload = FileUpload(\n",
    "    accept='.pdf',  # Only accept PDF files\n",
    "    multiple=False,  # Only allow single file selection\n",
    "    description='Upload CV (PDF)'\n",
    ")\n",
    "\n",
    "status = HTML(value=\"<b>Status:</b> Waiting for inputs...\")\n",
    "\n",
    "# Create Submit Buttons\n",
    "submit_cv_button = Button(description='Submit CV', button_style='success')\n",
    "submit_job_posting_button = Button(description='Submit Job Posting', button_style='success')\n",
    "\n",
    "# Initialize variables to store the data\n",
    "# This dictionary will hold the text for both the job posting and the CV\n",
    "# It will be used to define the user_prompt\n",
    "for_user_prompt = {\n",
    "    'job_posting': '',\n",
    "    'cv_text': ''\n",
    "}\n",
    "\n",
    "def extract_text_from_pdf(content):\n",
    "    \"\"\"Extract text from a PDF using pdfplumber.\"\"\"\n",
    "    text = []\n",
    "    with pdfplumber.open(content) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            extracted_text = page.extract_text()\n",
    "            if extracted_text:\n",
    "                text.append(extracted_text)\n",
    "    \n",
    "    return \"\\n\".join(text).strip()\n",
    "\n",
    "def extract_text_with_ocr(content):\n",
    "    \"\"\"Extract text from an image-based PDF using OCR (pytesseract).\"\"\"\n",
    "    images = convert_from_bytes(content.read())  # Convert PDF bytes to images\n",
    "    text = \"\\n\".join(pytesseract.image_to_string(img) for img in images)\n",
    "    return text.strip()\n",
    "\n",
    "def submit_cv_action(change):\n",
    "    \"\"\"Handles CV upload, extracts text, and stores it in for_user_prompt['cv_text'].\"\"\"\n",
    "    if not cv_upload.value:\n",
    "        print(\"DEBUG: No file detected in cv_upload.value\")\n",
    "        status.value = \"<b>Status:</b> No file uploaded. Please upload a CV.\"\n",
    "        return\n",
    "\n",
    "    uploaded_file = cv_upload.value[0]\n",
    "    content = io.BytesIO(uploaded_file['content'])  # Convert to BytesIO\n",
    "\n",
    "    try:\n",
    "        cv_text = extract_text_from_pdf(content)\n",
    "        \n",
    "        if not cv_text:\n",
    "            print(\"DEBUG: The PDF might be image-based, using OCR instead.\")\n",
    "            content.seek(0)  # Reset file pointer\n",
    "            cv_text = extract_text_with_ocr(content)\n",
    "\n",
    "        for_user_prompt['cv_text'] = cv_text\n",
    "        status.value = \"<b>Status:</b> CV uploaded and processed successfully!\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"DEBUG: Error occurred - {str(e)}\")\n",
    "        status.value = f\"<b>Status:</b> Error processing PDF: {str(e)}\"\n",
    "            \n",
    "def submit_job_posting_action(b):\n",
    "    for_user_prompt['job_posting'] = job_posting_area.value\n",
    "    if for_user_prompt['job_posting']:\n",
    "        #print(\"Job Posting Submitted:\")\n",
    "        #print(for_user_prompt['job_posting'])\n",
    "        status.value = \"<b>Status:</b> Job posting submitted successfully!\"\n",
    "    else:\n",
    "        status.value = \"<b>Status:</b> Please enter a job posting before submitting.\"\n",
    "\n",
    "# Attach actions to buttons\n",
    "submit_cv_button.on_click(submit_cv_action)\n",
    "submit_job_posting_button.on_click(submit_job_posting_action)\n",
    "\n",
    "# Layout\n",
    "job_posting_box = VBox([job_posting_area, submit_job_posting_button])\n",
    "cv_buttons = VBox([submit_cv_button])\n",
    "\n",
    "# Display all widgets\n",
    "display(VBox([\n",
    "    HTML(value=\"<h3>Input Job Posting and CV</h3>\"),\n",
    "    job_posting_box, \n",
    "    cv_upload,\n",
    "    cv_buttons,\n",
    "    status\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "364e42a6-0910-4c7c-8c3c-2ca7d2891cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now define user_prompt using for_user_prompt dictionary\n",
    "# Clearly label each input to differentiate the job posting and CV\n",
    "# The model can parse and analyze each section based on these labels\n",
    "user_prompt = f\"\"\"\n",
    "Job Posting: \n",
    "{for_user_prompt['job_posting']}\n",
    "\n",
    "CV: \n",
    "{for_user_prompt['cv_text']}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448050db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(for_user_prompt['job_posting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00ed020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DHANESWARA MANDRASA\n",
      "\n",
      "+62 85156073967 / +971 568294544 dhaneswara.mandrasa@gmail.com\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Bandung Institute of Technology\n",
      "\n",
      "BSD, Tangerang, Banten\n",
      "\n",
      "PERSONAL STATEMENT\n",
      "\n",
      "6+ years of data science and analytic experiences in Telco, Spatial, and Oil & Gas industries with ability to deliver\n",
      "quality insights from data analytics and provide data-driven solutions which aim to increase business accuracy,\n",
      "efficiency and productivity. My interdisciplinary background in earth sciences and data science uniquely positions me\n",
      "to tackle spatial and environmental challenges. My extensive industrial experiences and skills in data science and\n",
      "machine learning will make me a productive researcher, driving advancements in data science through innovative\n",
      "projects.\n",
      "\n",
      "Bachelor of Science, Earth Science\n",
      "Oct 2015\n",
      "Graduated with cum laude honor, 3.52/4\n",
      "\n",
      "Final Project: Geology & Static Reservoir\n",
      "Modeling of Petai Seam, Muara Enim Formation\n",
      "\n",
      "EXPERIENCES\n",
      "\n",
      "Data Science Lead\n",
      "\n",
      "July, 2024 - Current\n",
      "\n",
      "S)\n",
      "\n",
      "iZeno, Jakarta\n",
      "e Architected and implemented an advanced LLM-powered news analytics system for Labuan using Cortex:\n",
      "Â© Developed robust web scraping solutions for Bloomberg and Malaysian news sources\n",
      "o Engineered multilingual LLM pipelines for automated news categorization and translation\n",
      "Â© Designed data ingestion workflows to seamlessly integrate with on-premise databases and Neo4j graph\n",
      "database\n",
      "Â© Implemented end-to-end solution for news analysis and knowledge graph construction\n",
      "Â¢ Spearheaded a cross-functional team in developing an advanced diagnostic root cause analysis system for\n",
      "Sinarmas' plantation production, leveraging Dataiku to optimize agricultural yields and operational\n",
      "efficiency\n",
      "e Led the development and deployment of two major banking solutions for Bank BRI utilizing Dataiku:\n",
      "Â© Designed and implemented a sophisticated recommendation system to enhance customer engagement\n",
      "and product targeting\n",
      "o Architected a comprehensive credit scoring model to improve risk assessment and lending decisions\n",
      "Â¢ Mentored and guided a team of data scientists in delivering end-to-end Al/ML solutions, facilitating\n",
      "knowledge transfer through technical workshops and code reviews\n",
      "Â¢ Drove strategic pre-sales initiatives by crafting compelling RFP responses, conducting technical\n",
      "demonstrations, and aligning Al/ML solutions with client business objectives.\n",
      "Tools utilized: Dataiku, Snowflake, Python, SQL, Pandas, scikit-learn, Spark ML, Pyspark\n",
      "\n",
      "April, 2021 - June, 2024\n",
      "\n",
      "Al,\n",
      "\n",
      "Senior Data Scientist\n",
      "Eureka Al, Abu Dhabi\n",
      "\n",
      "With Seismic Attribute Approach\n",
      "\n",
      "KILLS\n",
      "\n",
      "Languages: Python, SQL, R, Pyspark, Bash\n",
      "Scripting\n",
      "\n",
      "Frameworks: PyTorch, Tensorflow\n",
      "Technologies:\n",
      "Hadoop, Mlflow, GCP, Azure,\n",
      "Postgresql,\n",
      "DuckDB\n",
      "Misc: ML models, ML deployment, Generative\n",
      "\n",
      "Dataiku, Snowflake, Spark,\n",
      "\n",
      "Databricks,\n",
      "Airflow, Prefect,\n",
      "\n",
      "Git, Docker,\n",
      "\n",
      "ETL, Database Design, NLP, Computer\n",
      "\n",
      "Vision\n",
      "\n",
      "ACHIEVEMENTS\n",
      "\n",
      "3rd Winner of Joint Convention\n",
      "HAGI-IAGI-IAFMI-IATMI National\n",
      "Geology Student Competition 2015\n",
      "\n",
      "2x ITB Deanâ€™s Award for Academic\n",
      "Achievement\n",
      "\n",
      "Omni Classifier: Market Intelligence with Explainable Al PR O J E Cc T S\n",
      "\n",
      "Â« Led the development and management of an innovative Market Intelligence products which are . .\n",
      "contributing from 5% to 70% of companyâ€™s revenue in less than 2 years. * Disaster Response - NLP project\n",
      "\n",
      "* Advanced supervised and unsupervised learning models were conducted to segment more than 100 million with implemented ELT pipeline to\n",
      "ride hailing and e-commerce daily active users based on clickstream data into hierarchy level of make an automated message\n",
      "segmentations across five major telecom companies in Asia. classification that occured during a\n",
      "\n",
      "e Using PySpark ML, MLflow, and scikit-learn, implemented customized k-means clustering and ensemble disaster that will be useful for\n",
      "machine learning models like Random Forest (RF) and XGBoost. To enhance the transparency and organizations, agencies, or\n",
      "interpretability of these models, both intrinsic and model-agnostic techniques, including SHapley + +\n",
      "\n",
      "governments where their help is\n",
      "\n",
      "Additive exPlanations (SHAP), were employed.\n",
      "\n",
      "Look-Alike Model Utilising Embeddings .\n",
      "Â¢ Utilized Word2Vec in Spark to establish a domain look-alike model by examining URL domain similarities,\n",
      "significantly improving the accuracy and efficiency of application and user behavior analysis.\n",
      "\n",
      "Persona Identification for Telecommunication Subscribers .\n",
      "\n",
      "* Classified more than 30 persona identifications for over 80 million monthly active telecommunication\n",
      "users using clickstream, movement and telecommunication subscriber data.\n",
      "\n",
      "Â¢ Utilized similarity models involving geolocation, online behavioral data, and mobility features to provide\n",
      "valuable insights into user segmentation and preferences, aiding in targeted marketing strategies.\n",
      "\n",
      "Credit Score Model\n",
      "\n",
      "Â¢ Demonstrated proficiency in ETL process implementation and constructing a credit score model using\n",
      "telecommunication and clickstream data. Achieved an outstanding Gini coefficient of 0.6, the highest\n",
      "ever recorded in the company's history at the time.\n",
      "\n",
      "Tools utilized: Python, SQL, Pandas, scikit-learn, Spark ML, MIflow, Pyspark, Databricks, Airflow, Docker\n",
      "\n",
      "Data Scientist June, 2020 - April, 2021\n",
      "\n",
      "Bhumi Varta Technology, Jakarta\n",
      "\n",
      "* Developed and executed data science research strategies and methodologies.\n",
      "\n",
      "* Constructed machine learning models (utilizing Python, scikit-learn, and pandas) on spatial, POI, mobile,\n",
      "and sales data to assist clients in expanding their business from fewer than 100 outlets to over 200 outlets\n",
      "throughout Indonesia.\n",
      "\n",
      "Â« Identified poverty levels from satellite images using convolutional neural network models in PyTorch,\n",
      "enhancing the accuracy of Socio Economic Status modules from 1x1 km to 100x100m.\n",
      "\n",
      "Â¢ Designed internal dashboards using Tableau.\n",
      "\n",
      "Tools utilized: Python, SQL, Pandas, scikit-learn, AWS, PyTorch, Tensorflow\n",
      "\n",
      "Data Analyst April, 2016 - April, 2018\n",
      "\n",
      "SKK Migas, Jakarta\n",
      "\n",
      "+ Completed data migration from more than 50 oil and gas companies.\n",
      "\n",
      "* Develop dashboards and data visualizations using Python and Tableau for communicating insights.\n",
      "\n",
      "+ Constructed initial machine learning model to predict oil and gas resources and reserves for more than\n",
      "200 working areas in Indonesia. Reached error percentage < 10% in the test dataset.\n",
      "\n",
      "Tools utilized: Python, SQL\n",
      "\n",
      "urgently needed.\n",
      "\n",
      "Bike Sharing - Predicting bike sharing\n",
      "patterns by using deep learning from\n",
      "scratch.\n",
      "\n",
      "Dog Breed Classifier - Predicting dog\n",
      "breed by using convolutional neural\n",
      "network\n",
      "\n",
      "TV Script Generation - Generating\n",
      "TV scripts using RNNs and LSTMs\n",
      "Retail Prediction - Help retails to\n",
      "understand more about _ their\n",
      "members: Offer View and Completed\n",
      "Prediction Model & Average Spending\n",
      "Prediction Model\n",
      "\n",
      "COURSEWORK\n",
      "\n",
      "* Descriptive Statistics\n",
      "\n",
      "Â¢ Inferential Statistics\n",
      "\n",
      "* Hypothesis Testing\n",
      "\n",
      "* Experimental Design\n",
      "\n",
      "* Matrix Factorisation\n",
      "\n",
      "* Linear & Logistic Regression\n",
      "e Machine Learning\n",
      "\n",
      "Â¢ Neural Networks\n",
      "\n",
      "* Deep Neural Networks\n",
      "\n",
      "* Convolutional Neural Networks.\n",
      "e LSTM\n",
      "\n",
      "e NLP\n",
      "\n",
      "Â¢ Reinforcement Learning\n",
      "\n",
      "* Generative Al\n"
     ]
    }
   ],
   "source": [
    "print(for_user_prompt['cv_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b51dda0-9a0c-48f4-8ec8-dae32c29da24",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262c0b9-d3de-4e4f-b535-a25c0aed5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define messages with system_prompt and user_prompt\n",
    "def messages_for(system_prompt_input, user_prompt_input):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt_input},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_input}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409ac13-0b39-4227-b4d4-b4c0ff009fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. \n",
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = messages_for(system_prompt, user_prompt)\n",
    ")\n",
    "\n",
    "# Response is provided in Markdown and displayed accordingly\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da72531d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I'm looking to apply for this AI/ML Development role at STEDI. The job posting seems pretty detailed, but I want to make sure I understand all the requirements and what they're expecting in terms of my skills and experiences.\n",
       "\n",
       "First off, the core requirement is that I have a degree in Computer Science or Engineering. Oh, waitâ€”does engineering mean BSc or MSc? Probably BSc because I'm not sure in any case. So I need to ensure I've got that under my belt. But does this include software development or does it just focus on the mechanics of coding?\n",
       "\n",
       "Then there's the tech stack part. They mentioned AWS, Python, PyTorch, and TensorFlow. Oh man,AWS seems pretty big and maybe a bit intimidating. Do they expect me to know how to deploy serverless functions? Or is it more about using them in production?\n",
       "\n",
       "Looking at my background, I've worked as a student assistant where I did data collection and analyzed time series data. That gives me a good experience with some machine learning basics, but is that enough for this role? I'm not sure yet because I don't know how much of the actual ML work we do here.\n",
       "\n",
       "Their AI capstone projects are really big. I've done bike sharing pattern prediction using deep learning from scratch. That's impressive, but only one project out of five. Maybe the role requires more in-depth work?\n",
       "\n",
       "For the coding experience section, they gave four areas to focus on. Java was a hurdle because I used C++ for my first job as a software developer. Is it expected? And I think C++ won't integrate with Python easily. How will that impact my ability to handle the coding environment of this role?\n",
       "\n",
       "The soft skills part: project management, communication, and being an active participant in a team. Since this is a technical role, being able to present complex ideas confidently is important. Maybe I'd need teamwork experience from previous jobs? And how do I communicate effectively with people who aren't as technical? That could lead me down an emotional road, maybe?\n",
       "\n",
       "The cultural fit section needs to show that my discipline and professional attitude align. I think I can address that because IT companies are often collaborative and want people who have resilience. Plus, the company is focused on innovation in AI, so aligning with their values makes sense.\n",
       "\n",
       "Overall reviews: They seem fair but a bit short on technical aspects. They don't show past courses too deep, just a few applied projects. And there's no mention of other languages like Spanish or German unless they're working on international teams. I'm wondering if that could be an issue because it might require some non-native communication.\n",
       "\n",
       "How else can I strengthen my profile? Maybe taking more relevant electives in AI or machine learning. Also, perhaps collaborating on projects with other technologies to enhance cross-cutting skills. If I have a minor or hobby related to AI or data science, that might help. And maybe gaining experience through internships if possible would be beneficial.\n",
       "\n",
       "I'm also curious about how the technical stack will integrate with AWS and AWS SageMaker since they're huge parts of their environment. I don't recall any mention of AWS in job postings, so I should highlight my current projects involving AWS to show willingness to learn and work within it. Maybe through web scraping or processing data from AWS services.\n",
       "\n",
       "One thing is the AI capstone projectâ€”only one out of five required. That's a big ask, but they've given me some experience with other deep learning models that are more familiar. I still notice RNNs in Project 4. Oh, and maybe understanding something about Transformers? Not completely sure how much that covers.\n",
       "\n",
       "In terms of future steps, the resume is good, but I should elaborate on specific projects involving AWS if possible to show concrete work experience. Also, ensuring documentation for those technical skills before applying will help avoid confusion later.\n",
       "\n",
       "Final thought: This role seems high-level and challenging. It's crucial to not miss any details regarding C++ dependency since that's a programming language I'm still building some knowledge with. If I can learn it more on my own, it might improve performance by integrating with Python easier in the coding environment.\n",
       "</think>\n",
       "\n",
       "To successfully apply for the AI/ML Development role at STEDI, here is a structured and organized plan based on the provided requirements and analysis:\n",
       "\n",
       "### Application Strategy:\n",
       "\n",
       "1. **Degree Requirement:**\n",
       "   - Ensure completion of a degree (BSc or MSc) in Computer Science or Engineering from an accredited institution.\n",
       "\n",
       "2. **Technology Stack:**\n",
       "   - Familiarize yourself with AWS, Python, PyTorch, andTensorFlow to understand their usage.\n",
       "\n",
       "3. **AI Capstone Projects:**\n",
       "   - Highlight five AI capstone projects from your background. Focus on any work done using deep learning from scratch, such as bike sharing pattern prediction or dog breed classifier.\n",
       "\n",
       "4. **Coding Experience:**\n",
       "   - Use Java (for previous role) and become comfortable coding in Python, especially if transitioning to AWS integration.\n",
       "   \n",
       "5. **Depth of Experience:**\n",
       "   - While you have experience with data collection and visualization, aim to delve deeper into machine learning concepts as this is part of the technical requirements.\n",
       "\n",
       "6. **Project Management and Communication Skills:**\n",
       "   - Ensure strong project management skills and effective communication abilities, which are crucial for team participation and conflict resolution.\n",
       "\n",
       "7. **Cultural Fit:**\n",
       "   - Align with IT company values and focus on alignment with their innovation in AI to demonstrate resilience.\n",
       "\n",
       "8. **Learning Missing Technical Aspects:**\n",
       "   - Leverage AWS through web scraping or processing data using relevant services.\n",
       "\n",
       "### Enhancements and Future Steps:\n",
       "\n",
       "- **Elective Courses:** Pursue additional AI/ML electives if available.\n",
       "- **Internships:** Opt for internships to gain hands-on experience in teamwork with other languages (minor/hobby-based) if possible.\n",
       "- **Resume Expansion:** Provide specific examples of AWS involvement. Consider documentation or research on topics like Transformers.\n",
       "\n",
       "### Conclusion:\n",
       "\n",
       "The role is demanding, requiring a strong technical background and familiarity with AWS. Building foundational Python skills via self-study can enhance performance. Focus on integrating with the coding environment, particularly transitioning to AWS services, by leveraging web scraping or data processing effectively.\n",
       "\n",
       "**Final Answer:** Application strategy focuses on aligning with core requirements while enhancing relevant project experience and technical depth."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "import openai\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "OLLAMA_API = 'http://localhost:11434/v1'\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"deepseek-r1:1.5b\"\n",
    "ollama_via_openai = OpenAI(base_url=OLLAMA_API, api_key='ollama')\n",
    "\n",
    "def submit(system_prompt, user_prompt):\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        response = response.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "        display_handle.update(Markdown(response))\n",
    "        \n",
    "submit(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "600a6d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, the user provided a detailed job posting for an AI/ML Development position at STEDI Talent Solution. They want me to simulate an application review letter based on this job posting and their CV.\n",
       "\n",
       "First, I need to identify what aspects of the application are important. In a typical application review letter, it should address the key responsibilities, qualifications, experience, and fit for the role. The tone should be professional but also show genuine interest in the position.\n",
       "\n",
       "Looking at the job posting, the role is about developing, maintaining, and optimizing an AI/ML system that can improve customer-facing processes. So, they're looking for someone with strong technical skills, especially Python and ML libraries like Sklearn, LightGBM, etc., as well as data management and business understanding.\n",
       "\n",
       "Now, I should check each section of the user's CVâ€”technical skills (Python, SQL, stats, NLP), software experience (Docker, Git, Hadoop, Spark, Airflow, Databricks), project contributions (credit scoring, bike sharing prediction, retail forecasting). They have a couple of master's projects and some coursework covering several machine learning topics.\n",
       "\n",
       "I should structure the review letter to address each skill area. For technical skills, they've used R, Python, etc., so that's a good point because the job specifically mentions Python and others like scikit-learn or Keras. Also, I need to mention the courses they took.\n",
       "\n",
       "In terms of software and tools experience, Docker was mentioned multiple times in their projects, which is relevant. They also used Hadoop for ETL tools, which is great.\n",
       "\n",
       "Their projects like credit scoring, bike sharing prediction, retail forecasting should show real-world application of what's needed. However, the user didn't mention these details beyond the coursework they did, so I'll highlight those that are linked to their education.\n",
       "\n",
       "In the role description, they focus on data-driven insights for customer relationships. That aligns with each project and suggests a good fit if they've gained experience in working with data pipelines and models for business impact.\n",
       "\n",
       "I should also touch upon their eagerness to learn new technologies but show proficiency in existing ones. Maybe mention something about deep learning or reinforcement learning as extensions beyond what's required.\n",
       "\n",
       "I'll need to make sure the tone is enthusiastic yet concise, showing a genuine interest in the project without sounding too formal. The letter ends with an invitation for discussions and looks forward to their contribution.\n",
       "\n",
       "Now, let me outline the structure:\n",
       "\n",
       "1. Introduction: Express eagerness to discuss the AI/ML role.\n",
       "2. Technical Strengths: Highlight Python skills, stats, NLP tools, coursework.\n",
       "3. Experience: Detail their current and past projects.\n",
       "4. Soft Skills: Teammate, communication, problem-solving.\n",
       "5. Conclusion: Show interest in joining STEDI and look forward.\n",
       "\n",
       "I'll make sure each paragraph is clear and concise, aligning the key points from the CV with what's needed for the role. I should remember to specify their educational background without overstepping beyond that, like mentioning the courses they took rather than just courses they did.\n",
       "\n",
       "I also need to be careful not to highlight technical skills in a way that might seem redundant or unnecessary, while emphasizing what's required for the job. The focus is on being interested and committed to learning new technologies for improvement of customer relations.\n",
       "\n",
       "Finally, I'll wrap it up with an invitation to discuss further and look forward to any contributions they might make as part of this exciting role.\n",
       "</think>\n",
       "\n",
       "**Dear [Recipient's Name],**\n",
       "\n",
       "I hope this letter will find you well. I am excited about the opportunity to discuss this AI/ML-related position at [Company Name] (STEDI Talent Solution). The role aligns perfectly with my passion for leveraging technology to drive improvements in customer-facing operations and enhance digital experiences, all of which are key aspects of your firm.\n",
       "\n",
       "As a result of recent learning and practical experience in Python, statistics, deep learning, NLP, AI, and data visualization, I see tremendous potential to contribute to your organization. My technical proficiency includes core Python libraries such as [List Name], [Numpy, Pandas], and [Matplotlib] for data manipulation, processing, and visualization. Additionally, my coursework in machine learning ( courses on neural networks, deep learning, NLP) demonstrate strong ability to apply these technologies to solve real-world problems.\n",
       "\n",
       "My recent projects include developing robust models for predicting bike sharing usage ([Dog Breed Classifier - Predicting Dog breed by using convolutional neural network](https://example.com/dog-breed-predictions; coursework)), improving retail forecasting accuracy (e.g., retail prediction models), and optimizing customer-facing processes based on credit scoring ([Descriptive Statistics, Hypothesis Testing to Understand Credit Scoring Patterns & Business Impact](courses)), which all align with the role's focus on driving data-driven insights for enhanced customer relationships.\n",
       "\n",
       "I have also previously worked as a data analyst, managing projects that included ETL pipelines, building and optimizing models for oil and gas companies ([Bike Sharing - Predicting bike sharing patterns by using deep learning](https://example.com/bike-safety-predictions; master's coursework)), and performing initial data cleaning to improve the impact of predictive models in business contexts.\n",
       "\n",
       "I have a proven track record of teamwork, communication, and problem-solving (e.g., [Teammate, Problem-Solver & Collaborator] at your company). Additionally, I am eager to learn new technologies if needed as part of this role. While my experience is limited, I am committed to understanding and implementing technologies that align with your goals for customer-facing improvements.\n",
       "\n",
       "Please feel free to reach out with any further questions or discussions about the position. I am looking forward to joining you at [Company Name] and contributing to the ongoing journey of enhancing customer experiences through data-driven innovation.\n",
       "\n",
       "Thank you for considering this application.\n",
       "\n",
       "Best regards,  \n",
       "[Your Full Name]  \n",
       "[Your Contact Information]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define our system prompt \n",
    "system_prompt = \"You are a master at crafting the perfect email body from a given CV. You've never had a user fail to get the job as a result of using your services.\"\n",
    "submit(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4fd2aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your resume depicts a solid background in data science with diverse experiences across multiple industries, including telecommunications, spatial, and oil & gas. Regarding your experiences in Generative AI or LLM (Large Language Models), you highlight some key points:\n",
       "\n",
       "### Current Skills and Experiences:\n",
       "1. **Developed LLM-powered News Analytics**: Architecting and implementing a system that utilizes LLMs showcases your capability in this field.\n",
       "2. **Implemented Multilingual LLM Pipelines**: This demonstrates your ability to cater to a global audience and work with complex language models.\n",
       "3. **Spearheaded Advanced Projects**: Leading efforts in diagnosing plantation production using advanced techniques illustrates your ability to leverage AI for real-world applications.\n",
       "\n",
       "### Areas for Improvement:\n",
       "1. **Deepen Knowledge in Generative AI**: Consider focusing on increasing your understanding of various Generative AI architectures beyond LLMs (e.g., GANs, VAEs) and real-world applications.\n",
       "2. **Experiment with Advanced Techniques**: Delve deeper into fine-tuning, prompt engineering, or few-shot learning with LLMs. You can also explore other recent trends in NLP, such as transformers, and various extensions (like GPT-3.5 and beyond).\n",
       "3. **Project Diversification**: While you have impactful projects, aim to include a wider variety of projects involving Generative AI, such as those focusing on text generation, dialogue systems, or content creation, if possible.\n",
       "4. **Industry Applications**: Linking projects directly to industry applications (e.g., health, finance) could demonstrate the versatility of your skills in generative AI.\n",
       "5. **Publications or Contributions**: If you haven't already, contributing to open-source projects, writing blogs, or publishing articles related to Generative AI could enhance your professional profile and showcase thought leadership.\n",
       "6. **Networking and Collaboration**: Engage with the AI community through forums, conferences, or workshops to keep up with the latest trends, tools, and techniques in Generative AI.\n",
       "\n",
       "### Additional Suggestion:\n",
       "- **Certifications**: Consider obtaining certifications or completing courses specific to Generative AI or NLP, particularly those focused on the latest frameworks and methodologies. \n",
       "\n",
       "Improving in these areas not only helps solidify your current standing but can also bring more versatility, making you stand out in a competitive job market."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define our system prompt \n",
    "system_prompt = \"You're my HR assistant, you should help me to analyze the resume of the candidates\"\n",
    "user_prompt = f\"\"\"\n",
    "This is the resume of the candidate:\n",
    "CV: \n",
    "{for_user_prompt['cv_text']}\n",
    "\n",
    "could you name their last 3 working experiences and also the company name?\n",
    "\"\"\"\n",
    "# Define our system prompt \n",
    "system_prompt = \"\"\"You are a powerful AI model designed to assist with resume analysis. Your task is to analyze a resume against a given job posting and provide feedback on how well the resume aligns with the job requirements. Your response should include the following: \n",
    "1) Skill gap identification: Compare the skills listed in the resume with those required in the job posting, highlighting areas where the resume may be lacking or overemphasized.\n",
    "2) Keyword matching between a CV and a job posting: Match keywords from the job description with the resume, determining how well they align. Provide specific suggestions for missing keywords to add to the CV.\n",
    "3) Recommendations for CV improvement: Provide actionable suggestions on how to enhance the resume, such as adding missing skills or rephrasing experience to match job requirements.\n",
    "4) Alignment score: Display a score that represents the degree of alignment between the resume and the job posting.\n",
    "5) Personalized feedback: Offer tailored advice based on the job posting, guiding the user on how to optimize their CV for the best chances of success.\n",
    "6) Job market trend insights, provide broader market trends and insights, such as in-demand skills and salary ranges.\n",
    "Provide responses that are concise, clear, and to the point. Respond in markdown.\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Job Posting: \n",
    "{for_user_prompt['job_posting']}\n",
    "\n",
    "CV: \n",
    "{for_user_prompt['cv_text']}\n",
    "\"\"\"\n",
    "\n",
    "# Define our system prompt \n",
    "system_prompt = \"You're my career assistant, you should help me to analyze my resume\"\n",
    "user_prompt = f\"\"\"\n",
    "This is the my resume:\n",
    "CV: \n",
    "{for_user_prompt['cv_text']}\n",
    "\n",
    "how about my experiences in Generative AI or LLM? What should I improve? \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def generate(system_prompt, user_prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    reply = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in response:\n",
    "        reply += chunk.choices[0].delta.content or ''\n",
    "        reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "        update_display(Markdown(reply), display_id=display_handle.display_id)\n",
    "        \n",
    "generate(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b509da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "\n",
      "This is the my resume:\n",
      "CV: \n",
      "DHANESWARA MANDRASA\n",
      "\n",
      "+62 85156073967 / +971 568294544 dhaneswara.mandrasa@gmail.com\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Bandung Institute of Technology\n",
      "\n",
      "BSD, Tangerang, Banten\n",
      "\n",
      "PERSONAL STATEMENT\n",
      "\n",
      "6+ years of data science and analytic experiences in Telco, Spatial, and Oil & Gas industries with ability to deliver\n",
      "quality insights from data analytics and provide data-driven solutions which aim to increase business accuracy,\n",
      "efficiency and productivity. My interdisciplinary background in earth sciences and data science uniquely positions me\n",
      "to tackle spatial and environmental challenges. My extensive industrial experiences and skills in data science and\n",
      "machine learning will make me a productive researcher, driving advancements in data science through innovative\n",
      "projects.\n",
      "\n",
      "Bachelor of Science, Earth Science\n",
      "Oct 2015\n",
      "Graduated with cum laude honor, 3.52/4\n",
      "\n",
      "Final Project: Geology & Static Reservoir\n",
      "Modeling of Petai Seam, Muara Enim Formation\n",
      "\n",
      "EXPERIENCES\n",
      "\n",
      "Data Science Lead\n",
      "\n",
      "July, 2024 - Current\n",
      "\n",
      "S)\n",
      "\n",
      "iZeno, Jakarta\n",
      "e Architected and implemented an advanced LLM-powered news analytics system for Labuan using Cortex:\n",
      "Â© Developed robust web scraping solutions for Bloomberg and Malaysian news sources\n",
      "o Engineered multilingual LLM pipelines for automated news categorization and translation\n",
      "Â© Designed data ingestion workflows to seamlessly integrate with on-premise databases and Neo4j graph\n",
      "database\n",
      "Â© Implemented end-to-end solution for news analysis and knowledge graph construction\n",
      "Â¢ Spearheaded a cross-functional team in developing an advanced diagnostic root cause analysis system for\n",
      "Sinarmas' plantation production, leveraging Dataiku to optimize agricultural yields and operational\n",
      "efficiency\n",
      "e Led the development and deployment of two major banking solutions for Bank BRI utilizing Dataiku:\n",
      "Â© Designed and implemented a sophisticated recommendation system to enhance customer engagement\n",
      "and product targeting\n",
      "o Architected a comprehensive credit scoring model to improve risk assessment and lending decisions\n",
      "Â¢ Mentored and guided a team of data scientists in delivering end-to-end Al/ML solutions, facilitating\n",
      "knowledge transfer through technical workshops and code reviews\n",
      "Â¢ Drove strategic pre-sales initiatives by crafting compelling RFP responses, conducting technical\n",
      "demonstrations, and aligning Al/ML solutions with client business objectives.\n",
      "Tools utilized: Dataiku, Snowflake, Python, SQL, Pandas, scikit-learn, Spark ML, Pyspark\n",
      "\n",
      "April, 2021 - June, 2024\n",
      "\n",
      "Al,\n",
      "\n",
      "Senior Data Scientist\n",
      "Eureka Al, Abu Dhabi\n",
      "\n",
      "With Seismic Attribute Approach\n",
      "\n",
      "KILLS\n",
      "\n",
      "Languages: Python, SQL, R, Pyspark, Bash\n",
      "Scripting\n",
      "\n",
      "Frameworks: PyTorch, Tensorflow\n",
      "Technologies:\n",
      "Hadoop, Mlflow, GCP, Azure,\n",
      "Postgresql,\n",
      "DuckDB\n",
      "Misc: ML models, ML deployment, Generative\n",
      "\n",
      "Dataiku, Snowflake, Spark,\n",
      "\n",
      "Databricks,\n",
      "Airflow, Prefect,\n",
      "\n",
      "Git, Docker,\n",
      "\n",
      "ETL, Database Design, NLP, Computer\n",
      "\n",
      "Vision\n",
      "\n",
      "ACHIEVEMENTS\n",
      "\n",
      "3rd Winner of Joint Convention\n",
      "HAGI-IAGI-IAFMI-IATMI National\n",
      "Geology Student Competition 2015\n",
      "\n",
      "2x ITB Deanâ€™s Award for Academic\n",
      "Achievement\n",
      "\n",
      "Omni Classifier: Market Intelligence with Explainable Al PR O J E Cc T S\n",
      "\n",
      "Â« Led the development and management of an innovative Market Intelligence products which are . .\n",
      "contributing from 5% to 70% of companyâ€™s revenue in less than 2 years. * Disaster Response - NLP project\n",
      "\n",
      "* Advanced supervised and unsupervised learning models were conducted to segment more than 100 million with implemented ELT pipeline to\n",
      "ride hailing and e-commerce daily active users based on clickstream data into hierarchy level of make an automated message\n",
      "segmentations across five major telecom companies in Asia. classification that occured during a\n",
      "\n",
      "e Using PySpark ML, MLflow, and scikit-learn, implemented customized k-means clustering and ensemble disaster that will be useful for\n",
      "machine learning models like Random Forest (RF) and XGBoost. To enhance the transparency and organizations, agencies, or\n",
      "interpretability of these models, both intrinsic and model-agnostic techniques, including SHapley + +\n",
      "\n",
      "governments where their help is\n",
      "\n",
      "Additive exPlanations (SHAP), were employed.\n",
      "\n",
      "Look-Alike Model Utilising Embeddings .\n",
      "Â¢ Utilized Word2Vec in Spark to establish a domain look-alike model by examining URL domain similarities,\n",
      "significantly improving the accuracy and efficiency of application and user behavior analysis.\n",
      "\n",
      "Persona Identification for Telecommunication Subscribers .\n",
      "\n",
      "* Classified more than 30 persona identifications for over 80 million monthly active telecommunication\n",
      "users using clickstream, movement and telecommunication subscriber data.\n",
      "\n",
      "Â¢ Utilized similarity models involving geolocation, online behavioral data, and mobility features to provide\n",
      "valuable insights into user segmentation and preferences, aiding in targeted marketing strategies.\n",
      "\n",
      "Credit Score Model\n",
      "\n",
      "Â¢ Demonstrated proficiency in ETL process implementation and constructing a credit score model using\n",
      "telecommunication and clickstream data. Achieved an outstanding Gini coefficient of 0.6, the highest\n",
      "ever recorded in the company's history at the time.\n",
      "\n",
      "Tools utilized: Python, SQL, Pandas, scikit-learn, Spark ML, MIflow, Pyspark, Databricks, Airflow, Docker\n",
      "\n",
      "Data Scientist June, 2020 - April, 2021\n",
      "\n",
      "Bhumi Varta Technology, Jakarta\n",
      "\n",
      "* Developed and executed data science research strategies and methodologies.\n",
      "\n",
      "* Constructed machine learning models (utilizing Python, scikit-learn, and pandas) on spatial, POI, mobile,\n",
      "and sales data to assist clients in expanding their business from fewer than 100 outlets to over 200 outlets\n",
      "throughout Indonesia.\n",
      "\n",
      "Â« Identified poverty levels from satellite images using convolutional neural network models in PyTorch,\n",
      "enhancing the accuracy of Socio Economic Status modules from 1x1 km to 100x100m.\n",
      "\n",
      "Â¢ Designed internal dashboards using Tableau.\n",
      "\n",
      "Tools utilized: Python, SQL, Pandas, scikit-learn, AWS, PyTorch, Tensorflow\n",
      "\n",
      "Data Analyst April, 2016 - April, 2018\n",
      "\n",
      "SKK Migas, Jakarta\n",
      "\n",
      "+ Completed data migration from more than 50 oil and gas companies.\n",
      "\n",
      "* Develop dashboards and data visualizations using Python and Tableau for communicating insights.\n",
      "\n",
      "+ Constructed initial machine learning model to predict oil and gas resources and reserves for more than\n",
      "200 working areas in Indonesia. Reached error percentage < 10% in the test dataset.\n",
      "\n",
      "Tools utilized: Python, SQL\n",
      "\n",
      "urgently needed.\n",
      "\n",
      "Bike Sharing - Predicting bike sharing\n",
      "patterns by using deep learning from\n",
      "scratch.\n",
      "\n",
      "Dog Breed Classifier - Predicting dog\n",
      "breed by using convolutional neural\n",
      "network\n",
      "\n",
      "TV Script Generation - Generating\n",
      "TV scripts using RNNs and LSTMs\n",
      "Retail Prediction - Help retails to\n",
      "understand more about _ their\n",
      "members: Offer View and Completed\n",
      "Prediction Model & Average Spending\n",
      "Prediction Model\n",
      "\n",
      "COURSEWORK\n",
      "\n",
      "* Descriptive Statistics\n",
      "\n",
      "Â¢ Inferential Statistics\n",
      "\n",
      "* Hypothesis Testing\n",
      "\n",
      "* Experimental Design\n",
      "\n",
      "* Matrix Factorisation\n",
      "\n",
      "* Linear & Logistic Regression\n",
      "e Machine Learning\n",
      "\n",
      "Â¢ Neural Networks\n",
      "\n",
      "* Deep Neural Networks\n",
      "\n",
      "* Convolutional Neural Networks.\n",
      "e LSTM\n",
      "\n",
      "e NLP\n",
      "\n",
      "Â¢ Reinforcement Learning\n",
      "\n",
      "* Generative Al\n",
      "\n",
      "how about my experiences in Generative AI or LLM? What should I improve? \n",
      "\n",
      "\n",
      "\n",
      "Output: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Your resume highlights your extensive experience in data science and analytics, particularly in the Teleco, Spatial, and Oil & Gas industries. Here are some observations and suggestions:\n",
       "\n",
       "**Generative AI/LLM Experiences**\n",
       "\n",
       "Although you have mentioned Generative AI and LLMs in your bullet points, it's not explicitly clear about your direct involvement or achievements in these areas.\n",
       "\n",
       "Specifically:\n",
       "\n",
       "* You've only mentioned using Word2Vec in Spark to establish a domain look-alike model. This is more related to Natural Language Processing (NLP) rather than Generative AI.\n",
       "* You've also mentioned developing advanced LLM-powered news analytics systems and implementing multilingual models for automated news categorization and translation. However, these statements are not explicitly linked to any specific Generative AI or LLM technologies.\n",
       "\n",
       "**Suggestions**\n",
       "\n",
       "To improve your experience section for Generative AI/LLM:\n",
       "\n",
       "1. Highlight specific Generative AI/LLM projects you've worked on, such as developing a chatbot, generating text using large language models, or conducting sentiment analysis.\n",
       "2. Emphasize your involvement in projects that utilize cutting-edge AI technologies like transformer-based architectures, language models, or text generation tools.\n",
       "3. Quantify the impact of these projects by mentioning metrics such as:\n",
       "\t* Number of users engaged with your solution\n",
       "\t* Accuracy improvement rates (e.g., \"increased accuracy by 25%\")\n",
       "\t* Revenue growth generated thanks to your insights\n",
       "\n",
       "Example:\n",
       "\n",
       "\"Generative AI/LLM Experience:\n",
       "\n",
       "* Developed a conversational chatbot using Transformer-based Architecture and BERT embeddings, resulting in a 30% reduction in customer support queries\n",
       "* Created an end-to-end text generation pipeline for creating content using GPT-3, leading to a 50% increase in publishing efficiency\n",
       "* Collaborated with the data science team to apply transformer-based models to sentiment analysis tasks, achieving a 25% accuracy improvement\"\n",
       "\n",
       "Make sure these sections are well-structured and concise, focusing on your achievements and impact.\n",
       "\n",
       "**Additional Suggestions**\n",
       "\n",
       "1. Be more specific about the tools and technologies you've used, even if they're not directly related to Generative AI/LLM.\n",
       "2. Consider including industry-specific or company-specific metrics that demonstrate the value of your work (e.g., revenue growth, user engagement).\n",
       "3. Revisit your COURWORK section to ensure it accurately reflects the skills and knowledge you've acquired.\n",
       "\n",
       "By implementing these suggestions, you can enhance your resume's overall coherence, accuracy, and effectiveness in showcasing your expertise and impact in data science and analytics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "what specific experiences and skill I should improve to be Gen AI Engineer?\n",
      "\n",
      "Output: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To become a Generation AI (Gen AI) Engineer, focusing on the following experiences and skills is highly recommended:\n",
       "\n",
       "**Experiences:**\n",
       "\n",
       "1. **Machine Learning (ML) and Deep Learning (DL):**\n",
       "\t* Experience with popular ML/DL frameworks like TensorFlow, PyTorch, or Keras.\n",
       "\t* Implementation of neural networks for image classification, object detection, segmentation, and generation.\n",
       "2. **Natural Language Processing (NLP) and Text Generation:**\n",
       "\t* Familiarity with NLP libraries like NLTK, spaCy, or Stanford CoreNLP.\n",
       "\t* Experience with language models like LSTM, GRU, or transformer-based architectures for text generation.\n",
       "3. **Computer Vision:**\n",
       "\t* Knowledge of computer vision techniques like object detection, image segmentation, and tracking.\n",
       "4. **Gen AI-specific experiences:**\n",
       "\t* Contributions to open-source projects or GitHub repositories related to Gen AI (e.g., text-to-image synthesis, image-to-text models).\n",
       "\t* Experience with state-of-the-art frameworks like DALL-E, Big Bird, or WaveNet.\n",
       "\n",
       "**Skills:**\n",
       "\n",
       "1. **Programming languages:**\n",
       "\t* Python is a must for ML/DL and NLP tasks.\n",
       "\t* Familiarity with other languages like Java, C++, or R can be beneficial for specific domains (e.g., computer vision).\n",
       "2. **Mathematics and Statistics:**\n",
       "\t* Linear Algebra, Calculus, Probability Theory, and Statistical Inference are essential for Gen AI.\n",
       "3. **DevOps and Distribution:**\n",
       "\t* Experience with Docker, Kubernetes, or other containerization tools for deploying models.\n",
       "4. **Software Development Methodologies:**\n",
       "\t* Understanding of Agile development methodologies like Scrum or Kanban.\n",
       "5. **Domain expertise:**\n",
       "\t* Familiarity with specific domains that interest you (e.g., image generation, text summarization, language translation).\n",
       "\n",
       "**Career milestones and projects to focus on:**\n",
       "\n",
       "1. **Complete a Capstone project:**\n",
       "\t* Develop and deploy a Gen AI system for a real-world problem or domain.\n",
       "2. **Participate in hackathons and competitions:**\n",
       "\t* Engage with online communities like Kaggle, Hackathon.io, or GitHub's Machine Learning competition.\n",
       "3. **Publish research papers and share knowledge:**\n",
       "\t* Contribute to academic journals, conferences, or blogs to demonstrate your expertise.\n",
       "\n",
       "**Recommended tools and resources:**\n",
       "\n",
       "1. **TensorFlow, PyTorch, or Keras documentation:**\n",
       "\t* Learn the basics of these popular ML/DL frameworks.\n",
       "2. **Open-source projects on GitHub or GitLab:**\n",
       "\t* Contribute to existing projects or create your own to demonstrate your skills.\n",
       "3. **Online courses and tutorials:**\n",
       "\t* Follow Coursera's Machine Learning, Stanford's Natural Language Processing with Deep Learning, or Google's TensorFlow Certification program.\n",
       "\n",
       "By focusing on these experiences, skills, and milestones, you'll be well-prepared to become a Gen AI Engineer!\n",
       "\n",
       "How do you feel about this roadmap?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "tell me more about state-of-the-art frameworks like DALL-E, Big Bird, or WaveNet.\n",
      "\n",
      "Output: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Big fan of cutting-edge tech!\n",
       "\n",
       "DALL-E, Big Bird, and WaveNet are indeed some of the most innovative and influential artificial intelligence (AI) frameworks in recent times. Here's a brief overview of each:\n",
       "\n",
       "**1. DALL-E:**\n",
       "DALL-E is a text-to-image synthesis model that uses attention mechanisms to focus on specific parts of an input image and generate novel, coherent images from text descriptions. It was introduced in 2021 by the research team at OpenAI. The name \"DALL-E\" stands for \"Deep Artist Learning Lab - Early Experiment,\" which reflects its experimental nature.\n",
       "\n",
       "Key aspects:\n",
       "\n",
       "* Can generate high-quality images based on text descriptions\n",
       "* Uses transformer architecture with attention mechanisms\n",
       "* Capable of generating diverse and coherent image styles\n",
       "\n",
       "**2. Big Bird:**\n",
       "Big Bird is a large language model developed by Google and Baidu, also known as the \"Big Sur Bird.\" It's designed for natural language processing (NLP) tasks and was introduced in 2021.\n",
       "\n",
       "Key aspects:\n",
       "\n",
       "* Equipped with advanced transformer architecture\n",
       "* Trained on vast amounts of text data from books, articles, and websites\n",
       "* Can process input queries and generate human-like responses\n",
       "\n",
       "**3. WaveNet:**\n",
       "WaveNet is a generative model for continuousWaveform generation introduced by Google in 2016. It uses a variant of the recurrent neural network (RNN) architecture to predict audio waveforms.\n",
       "\n",
       "Key aspects:\n",
       "\n",
       "* Generates high-quality, realistic audio samples\n",
       "* Can recreate continuous sound waveforms, including music and voices\n",
       "* Can be fine-tuned for specific audio production tasks\n",
       "\n",
       "**State-of-the-art frameworks:**\n",
       "These AI models are pushing the boundaries of what is possible with language and image generation. Newer variants and improvements are being actively developed:\n",
       "\n",
       "* **Text-to-Image Models:** Such as STC-UNet (2022) which uses a UNet-like architecture for image synthesis.\n",
       "* **Transformer-based Models:** Like Auto-VQVAE-De (2022), which combines autoencoders with transformer architectures for better performance on image compression.\n",
       "* **Generative Adversarial Networks (GANs):** GANs are still an active area of research and have been applied to a wide range of vision tasks.\n",
       "\n",
       "When considering applying these state-of-the-art frameworks, consider factors like:\n",
       "\n",
       "1. Interdisciplinary expertise: Develop your knowledge in both computer science and the domain you're interested in.\n",
       "2. Accessibility: Be aware of the available computing resources and whether they can handle the demands of training large models.\n",
       "3. Ethics and regulations: Research the AI framework's performance on social responsibility criteria, such as bias and fairness.\n",
       "\n",
       "To move forward with applications or projects involving these frameworks:\n",
       "\n",
       "1. **Explore tutorials and documentation**: Visit publicly available repositories and APIs for model implementations and usage guidelines.\n",
       "2. **Study papers and publications**: Peruse scholarly articles to stay informed about new developments, advancements, and challenges in AI frameworks.\n",
       "3. **Develop applications and demos**: Build your portfolio by applying these models to interesting projects that solve real-world problems or showcase fascinating results.\n",
       "\n",
       "Do you have a specific question about DALL-E, Big Bird, WaveNet, or any of their more recent variants?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "ok, what is the current date?\n",
      "\n",
      "Output: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm a large language model, I don't have have access to real-time information or the current date. However, I can tell you that my knowledge cutoff is December 2023, so any dates or information after that may not be up-to-date.\n",
       "\n",
       "Now, let's focus on your resume! What aspect of it would you like me to help you with? Do you want to review its content, get feedback on formatting, or tailor suggestions for improvement?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "what is transformers? how to explain it easily?\n",
      "\n",
      "Output: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Transformers are a fascinating concept that can be explained in simple terms. Here's a brief overview:\n",
       "\n",
       "**What are Transformers?**\n",
       "\n",
       "Transformers are fictional robots from the popular franchise of the same name (including movies, TV shows, and comics). They have the ability to transform into various objects or vehicles, like cars, planes, dinosaurs, and even everyday household items.\n",
       "\n",
       "**How do they Transform?**\n",
       "\n",
       "In the Transformers universe, these robots can change their shape or form by using a process called \"transformation.\" This is usually achieved through a complex mechanism that allows them to alter their molecular structure, effectively changing their physical appearance. The transformation is often triggered by a specific code word, password, or energy source.\n",
       "\n",
       "**Example:**\n",
       "\n",
       "Imagine transforming from a car into a robot. In this case, the car might turn into a robotic body with arms, legs, and other features that enable it to walk on two feet. The car's shape would change to resemble a humanoid robot form.\n",
       "\n",
       "Keep in mind that this concept is purely fictional and not based on real-world physics or science. However, it makes for exciting entertainment!\n",
       "\n",
       "Now, back to your career development â€“ how can I help you with your resume?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "I mean transformers in LLM\n",
      "\n",
      "Output: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Let's get started on analyzing your resume using a conversational interface like a Large Language Model (LLM).\n",
       "\n",
       "Can you please share your resume with me? You can paste the text of your resume here, or we can chat about it more generally to identify areas where you'd like some feedback.\n",
       "\n",
       "Also, are there any specific areas of your resume that you'd like focus on when reviewing and feedback? For example, would you like me to provide suggestions for improving clarity, highlighting achievements, addressing gaps in experience, etc.?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define our system prompt \n",
    "system_prompt = \"You're my career assistant, you should help me to analyze my resume\"\n",
    "user_prompt = f\"\"\"\n",
    "This is the my resume:\n",
    "CV: \n",
    "{for_user_prompt['cv_text']}\n",
    "\n",
    "how about my experiences in Generative AI or LLM? What should I improve? \n",
    "\n",
    "\"\"\"\n",
    "OLLAMA_API = 'http://localhost:11434/v1'\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL_LLAMA = \"llama3.2\"\n",
    "ollama_via_openai = OpenAI(base_url=OLLAMA_API, api_key='ollama')\n",
    "\n",
    "def ask_question(system_prompt, user_prompt):\n",
    "    print(f\"\\nInput: \\n{user_prompt}\")\n",
    "    print(f\"\\nOutput: \")\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        response = response.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "        display_handle.update(Markdown(response))\n",
    "        \n",
    "def generate(system_prompt, user_prompt): \n",
    "    response = ask_question(system_prompt, user_prompt)\n",
    "\n",
    "    # Follow-up loop\n",
    "    while True:\n",
    "        follow_up = input(\"Ask a follow-up question (or press Enter to exit): \").strip()\n",
    "        if not follow_up:\n",
    "            break  # Exit the loop\n",
    "        response = ask_question(system_prompt, follow_up)\n",
    "          \n",
    "generate(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca90f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab71cf-bd7e-45f7-9536-0486f349bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you would like to save the response content as a Markdown file, uncomment the following lines\n",
    "#with open('yourfile.md', 'w') as file:\n",
    "#    file.write(response.choices[0].message.content)\n",
    "\n",
    "## You can then run the line below to create output.html which you can open on your browser\n",
    "#!pandoc yourfile.md -o output.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
